{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57fdd5b4",
   "metadata": {},
   "source": [
    "#### Topic: Financial Data Science Template <br> Author: Dhruv Singh <br> Date Updated: 7/23/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f614e300",
   "metadata": {},
   "source": [
    "# Data Science Project Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb637d70",
   "metadata": {},
   "source": [
    "### Step 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b865c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import eikon as ek\n",
    "#from dotenv import load_dotenv\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2fd93d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting api key\n",
    "'''\n",
    "load_dotenv(\"eikon.env\")\n",
    "eikon_api_key = os.getenv(\"eikon_api_key\")\n",
    "ek.set_app_key(eikon_api_key)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19f7ee",
   "metadata": {},
   "source": [
    "### Step 1: Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a43648e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "rics = ['JPM', 'BAC', 'WFC', 'MS', 'GS', 'C', 'BCS']\n",
    "df_banks = ek.get_timeseries(rics,\n",
    "                          fields='CLOSE',\n",
    "                          start_date='2000-10-01',\n",
    "                          interval='monthly')\n",
    "df_banks.to_csv('0_readonly/banks_data.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "394e263a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# banks\n",
    "df = pd.read_csv('0_readonly/banks_data.csv', index_col='Date', parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d29724",
   "metadata": {},
   "source": [
    "#### Part 1: Summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77b85add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(273, 7)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "JPM    float64\n",
       "BAC    float64\n",
       "WFC    float64\n",
       "MS     float64\n",
       "GS     float64\n",
       "C      float64\n",
       "BCS    float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "JPM    0\n",
       "BAC    0\n",
       "WFC    0\n",
       "MS     0\n",
       "GS     0\n",
       "C      0\n",
       "BCS    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dimensions\n",
    "display(df.shape)\n",
    "\n",
    "# data types\n",
    "display(df.dtypes)\n",
    "\n",
    "# null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51e56ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>JPM</th>\n",
       "      <th>BAC</th>\n",
       "      <th>WFC</th>\n",
       "      <th>MS</th>\n",
       "      <th>GS</th>\n",
       "      <th>C</th>\n",
       "      <th>BCS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>273.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>66.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>37.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>94.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>170.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>414.0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         JPM    BAC    WFC     MS     GS      C    BCS\n",
       "count  273.0  273.0  273.0  273.0  273.0  273.0  273.0\n",
       "mean    66.0   28.0   37.0   45.0  175.0  187.0   20.0\n",
       "std     37.0   13.0   11.0   20.0   78.0  192.0   13.0\n",
       "min     19.0    4.0   12.0   13.0   66.0   15.0    5.0\n",
       "25%     38.0   16.0   28.0   31.0  109.0   47.0   10.0\n",
       "50%     47.0   28.0   34.0   42.0  164.0   64.0   16.0\n",
       "75%     94.0   38.0   48.0   52.0  211.0  433.0   28.0\n",
       "max    170.0   54.0   66.0  104.0  414.0  560.0   54.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarizing numeric data\n",
    "df.describe().round(0) # .describe(include=all) fpr categorical variables to be included"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e715ec76",
   "metadata": {},
   "source": [
    "#### Part 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8076bc60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c48ab8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9971d155",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eeef44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcfba78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2aae12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b102ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b84f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72030230",
   "metadata": {},
   "source": [
    "Basics 2: Merge / Concat\n",
    "* Concatenate vertically: df_concat = pd.concat[df1, df2, df3] \n",
    "* Merge horizontally: set both indices, df_merge = pd.merge(df1, df2, how = 'inner / left / outer', left_index=True, right_index=True \n",
    "\n",
    "Notes:\n",
    "* Can only merge 2 dfs at a time\n",
    "* Make sure all columns are aligned before concatenating, can drop or insert 'empty' columns to do so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be22b1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da79d76",
   "metadata": {},
   "source": [
    "Basics 3: Cleaning Variables\n",
    "* Strip out special characters from strings: df[\"column\"] = df[\"column\"].str.replace(',', '')\n",
    "* Convert data to appropriate types (int, float): df[\"column\"] = df[\"column\"].astype('float/int')\n",
    "* Convert string to datetime: df.column = pd.to_datetime(df.column)\n",
    "* Recode Categories: df.loc[condition, 'column'] = value\n",
    "* Impute missing values: df.fillna(value / 0 / df.median(), inplace=True) # uses column medians\n",
    "* Drop irrelevant columns: df.drop(columns=['A', 'B'], inplace=True)\n",
    "* Rename Columns: df = df.rename(columns = {\"A_old\": \"A_new\", \"B_old\": \"B_new\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c62914",
   "metadata": {},
   "source": [
    "Basics 4: Working with datetime variables\n",
    "1. Splitting date columns into date and time\n",
    "* df['date'] = pd.to_datetime(df['datetime']).dt.date\n",
    "* df['day'] = pd.to_datetime(df['datetime']).dt.weekday\n",
    "* df['time'] = pd.to_datetime(df['datetime']).dt.time\n",
    "\n",
    "2. Creating month and year columns\n",
    "* df['year'] = pd.DatetimeIndex(df['date']).year.fillna(0).astype(int)\n",
    "* df['month'] = pd.DatetimeIndex(df['date\"']).month.fillna(0).astype(int)\n",
    "\n",
    "3. Creating year-month variable\n",
    "* df['year_month'] = df['year'].map(str) + '-' + df['month'].map(str)\n",
    "* df['year_month'] = pd.to_datetime(df['year_month'], format='%Y-%m').dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd4cff4",
   "metadata": {},
   "source": [
    "### Step 2: EDA, basic (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074bf7e0",
   "metadata": {},
   "source": [
    "* Summarize all numeric variables: df.describe().round(2)\n",
    "* Groupbys: df_agg = df[['col1', 'col2', 'col3']].groupby(['col1', 'col2']).agg(['count', 'sum'])\n",
    "* Nested headers: df.columns = df.columns.get_level_values(1)\n",
    "* Reshape, long to wide: (see below)\n",
    "* Reshape, wide to long: df_long = pd.melt(df, id_vars=df.columns[0:m], value_vars=df.columns[m:n])\n",
    "\n",
    "Notes: \n",
    "* Rename columns after groupby\n",
    "* In melt, id vars stay fixed, value columns get stacked next to their column headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f26c82",
   "metadata": {},
   "source": [
    "![alt text](reshape.png)\n",
    "\n",
    "Source: https://towardsdatascience.com/reshape-pandas-dataframe-with-pivot-table-in-python-tutorial-and-visualization-2248c2012a31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb127aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df758b01",
   "metadata": {},
   "source": [
    "### Step 3: Visualize Data || Reshape It (15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b78a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9aaa54",
   "metadata": {},
   "source": [
    "#### 1. Bar graph: 1 category\n",
    "\n",
    "plt.style.use('ggplot') <br>\n",
    "x = df.index.tolist()\n",
    "\n",
    "* ticks <br>\n",
    "\n",
    "x_pos = [i for i, _ in enumerate(x)] <br>\n",
    "plt.bar(x_pos, df['Enrollments'], color='green') <br>\n",
    "plt.xlabel(\"categorical var\") <br>\n",
    "plt.ylabel(\"numeric var\") <br>\n",
    "plt.title(\"graph title\")\n",
    "\n",
    "plt.xticks(x_pos, x)\n",
    "\n",
    "plt.savefig('directory/name.png', dpi=300, bbox_inches='tight') <br>\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3968232",
   "metadata": {},
   "source": [
    "#### 2. Bar graph: multiple categories\n",
    "\n",
    "* setting figure size\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "* number of ticks\n",
    "\n",
    "N = 3\n",
    "ind = np.arange(N) \n",
    "\n",
    "* width of bars\n",
    "\n",
    "width = 0.1\n",
    "\n",
    "* axes and title\n",
    "\n",
    "plt.title(\" ──────── graph name ──────── \", fontsize=20 ,fontweight=\"bold\")\n",
    "plt.xlabel(\"category\", fontsize=15)\n",
    "plt.ylabel(\"numeric var\", fontsize=15)\n",
    "\n",
    "* bar chart data\n",
    "\n",
    "bar1 = plt.bar(ind, df['col1'], width, color = 'tab:green', edgecolor = \"black\", linewidth=1)  <br>\n",
    "bar2 = plt.bar(ind-width, df['col2'], width, color = 'tab:cyan', edgecolor = \"black\", linewidth=1) <br>\n",
    "bar3 = plt.bar(ind+width, df['col3'], width, color = 'tab:blue', edgecolor = \"black\", linewidth=1) <br>\n",
    "bar4 = plt.bar(ind-width*2, df['col4'], width, color = 'tab:purple', edgecolor = \"black\", linewidth=1) <br>\n",
    "bar5 = plt.bar(ind+width*2, df['col5'], width, color = 'tab:red', edgecolor = \"black\", linewidth=1) <br>\n",
    "bar6 = plt.bar(ind-width*3, df['col6'], width, color = 'tab:brown', edgecolor = \"black\", linewidth=1) <br>\n",
    "bar7 = plt.bar(ind+width*3, df['col7'], width, color = 'tab:orange', edgecolor = \"black\", linewidth=1) <br>\n",
    "bar8 = plt.bar(ind-width*4, df['col8'], width, color = 'tab:olive', edgecolor = \"black\", linewidth=1) <br>\n",
    "bar9 = plt.bar(ind+width*4, df['col9'], width, color = 'tab:gray', edgecolor = \"black\", linewidth=1)\n",
    "\n",
    "* Hide the right and top spines\n",
    "\n",
    "plt.gca().spines.right.set_visible(False)\n",
    "plt.gca().spines.top.set_visible(False)\n",
    "\n",
    "* ticks\n",
    "\n",
    "plt.xticks(ind, df['categorical var'], fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "* legend\n",
    "\n",
    "plt.legend((bar1, bar2, bar3, bar4, bar5, bar6, bar7, bar8, bar9), \n",
    "           ('label1', 'label2', 'label3', 'label4', 'label5', 'label6', 'label7', 'label8', 'label9'), \n",
    "           loc='lower center',title_fontsize=10, fontsize=10, bbox_to_anchor=(0.5, -0.25), ncol=5, frameon=False)\n",
    "\n",
    "* saving chart\n",
    "\n",
    "plt.savefig('directory/name.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c149f9d",
   "metadata": {},
   "source": [
    "#### 3. Histogram\n",
    "\n",
    "plt.hist(df['variable']) <br>\n",
    "plt.savefig('name.png', dpi=300, bbox_inches='tight') <br>\n",
    "plt.title('graph name') <br>\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058779c7",
   "metadata": {},
   "source": [
    "#### 4. Binning Variables\n",
    "\n",
    "bins = [lower_lim_inclusive, cutpt1, cutpt2, cutpt3, ... cutptn, upper_lim_notinclusive] <br>\n",
    "labels = ['label1', 'label2', ... 'labeln'] <br>\n",
    "df['var_binned'] = pd.cut(df['continuous_var'], bins=bins, labels=labels, include_lowest=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfabd94",
   "metadata": {},
   "source": [
    "#### 5. Line Graph\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "* x axis ticks\n",
    "\n",
    "xcoords = ['tick1', 'tick2',..., 'tickn']\n",
    "\n",
    "* axes and title\n",
    "\n",
    "ax.set_title(\"───────────── graph name ─────────────\", fontsize=20 ,fontweight=\"bold\") <br>\n",
    "ax.set_xlabel(\"category\", fontsize=15) <br>\n",
    "ax.set_ylabel(\"numeric variable\", fontsize=15)\n",
    "\n",
    "* Hide the right and top spines\n",
    "\n",
    "ax.spines.right.set_visible(False) <br>\n",
    "ax.spines.top.set_visible(False)\n",
    "\n",
    "* ticks\n",
    "\n",
    "ax.tick_params(axis='x', which='major', labelsize=10, rotation = 45) <br>\n",
    "ax.tick_params(axis='y', which='major', labelsize=10)\n",
    "\n",
    "* creating plot    \n",
    "\n",
    "ax.plot(df['datetime_var'], df['numeric var'], label = 'line label', linewidth=3, color='steelblue')\n",
    "\n",
    "* creating vertical lines\n",
    "\n",
    "for xc in xcoords:\n",
    "    ax.axvline(x=pd.to_datetime(xc), color='black', linestyle=':')\n",
    "\n",
    "* legend\n",
    "\n",
    "ax.legend(loc='center left',title_fontsize=20, fontsize=20, bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "* saving out plot\n",
    "\n",
    "plt.savefig('directory/name.png', dpi=300, bbox_inches='tight') <br>\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ae918c",
   "metadata": {},
   "source": [
    "#### 6. Line Graph: Multiple\n",
    "\n",
    "* converting string to datetime\n",
    "\n",
    "df.Date = pd.to_datetime(df.Date)  <br>\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "* axes and title\n",
    "\n",
    "ax.set_title(\" ──── graph name ──── \", fontsize=20 ,fontweight=\"bold\") <br>\n",
    "ax.set_xlabel(\"categorical var\", fontsize=15) <br>\n",
    "ax.set_ylabel(\"numeric var\", fontsize=15)\n",
    "\n",
    "* Hide the right and top spines\n",
    "\n",
    "ax.spines.right.set_visible(False) <br>\n",
    "ax.spines.top.set_visible(False)\n",
    "\n",
    "* ticks\n",
    "\n",
    "ax.tick_params(axis='x', which='major', labelsize=12, rotation = 45) <br>\n",
    "ax.tick_params(axis='y', which='major', labelsize=12)\n",
    "\n",
    "* creating plot    \n",
    "\n",
    "ax.plot(df['Date'], df['var1'], label = 'name1', linewidth=2, color='gray') <br>\n",
    "ax.plot(df['Date'], df2['var2'], label = 'name2)', linewidth=2, color='orange') <br>\n",
    "ax.plot(df['Date'], df3['var3'], label = 'name3', linewidth=2, color='steelblue')\n",
    "\n",
    "* limiting x-axis, post 2-13\n",
    "\n",
    "ax.set_xlim(pd.to_datetime('yyyy-mm-dd'), pd.to_datetime('yyyy-mm-dd'))\n",
    "\n",
    "* creating vertical lines, annotating\n",
    "\n",
    "ax.axvline(x=pd.to_datetime('yyyy-mm-dd'), color='black', linestyle='--') <br>\n",
    "ax.axvline(x=pd.to_datetime('yyyy-mm-dd'), color='black', linestyle='--') <br>\n",
    "ax.axvline(x=pd.to_datetime('yyyy-mm-dd'), color='black', linestyle='--')\n",
    "\n",
    "* legend\n",
    "\n",
    "ax.legend(loc='lower center',title_fontsize=10, fontsize=10, bbox_to_anchor=(0.5, -0.25), ncol=3, frameon=False)\n",
    "\n",
    "* saving out plot\n",
    "\n",
    "plt.savefig('directory/2.name.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca6b2c2",
   "metadata": {},
   "source": [
    "#### 7. Scatter + Fitted Line\n",
    "\n",
    "* setting plot dimensions\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "* creating plot\n",
    "\n",
    "ax = sns.regplot(x='numeric var 1', y='numeric var 2', data=df, color='steelblue', marker='o', scatter_kws={'s': 70})\n",
    "\n",
    "* axes and title\n",
    "\n",
    "ax.set_title(\"──────── graph name ────────\", fontsize=20 ,fontweight=\"bold\") <br>\n",
    "ax.set_xlabel(\"label 1\", fontsize=15) <br>\n",
    "ax.set_ylabel(\"label 2\", fontsize=15)\n",
    "\n",
    "* Hide the right and top spines\n",
    "\n",
    "ax.spines.right.set_visible(False) <br>\n",
    "ax.spines.top.set_visible(False)\n",
    "\n",
    "* ticks\n",
    "\n",
    "ax.tick_params(axis='x', which='major', labelsize=10) <br>\n",
    "ax.tick_params(axis='y', which='major', labelsize=10)\n",
    "\n",
    "* label limits\n",
    "\n",
    "ax.set_xlim(0, m) <br>\n",
    "ax.set_ylim(0, n)\n",
    "\n",
    "* saving out plot\n",
    "\n",
    "plt.savefig('directory/name.png', dpi=300, bbox_inches='tight') <br>\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6779a147",
   "metadata": {},
   "source": [
    "#### 8. Box Plots\n",
    "\n",
    "* setting plot dimensions\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "* creating plot\n",
    "\n",
    "ax = sns.boxplot(x=\"categorical variable\", y=\"numeric variable\", data=df)\n",
    "\n",
    "* axes and title\n",
    "\n",
    "ax.set_title(\"───────────────── graph name ─────────────────\", fontsize=30,fontweight=\"bold\") <br>\n",
    "ax.set_xlabel(\"category\", fontsize=25,fontweight=\"bold\") <br>\n",
    "ax.set_ylabel(\"numeric var\", fontsize=25,fontweight=\"bold\")\n",
    "\n",
    "* Hide the right and top spines\n",
    "\n",
    "ax.spines.right.set_visible(False) <br>\n",
    "ax.spines.top.set_visible(False)\n",
    "\n",
    "* ticks\n",
    "\n",
    "ax.tick_params(axis='x', which='major', labelsize=20) <br>\n",
    "ax.tick_params(axis='y', which='major', labelsize=20)\n",
    "\n",
    "* saving out plot\n",
    "\n",
    "plt.savefig('2_graphs/8_Region_Distribution.png', dpi=300, bbox_inches='tight') <br>\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93749c82",
   "metadata": {},
   "source": [
    "### Step 4: Advanced EDA (15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383833fc",
   "metadata": {},
   "source": [
    "* Correlation matrix:\n",
    "\n",
    "corr = df_num.corr() <br>\n",
    "corr\n",
    "\n",
    "* Heatmap:\n",
    "\n",
    "plt.figure(figsize = (12,12)) <br>\n",
    "sns.heatmap((corr), annot = True)\n",
    "\n",
    "\n",
    "* Feature importance regressor / classifier:\n",
    "* Dimensionality Reduction: \n",
    "* Visualize most important features:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b0406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957edd31",
   "metadata": {},
   "source": [
    "#### Feature Importance: Random Forest Regressor\n",
    "\n",
    "* Prepare Data\n",
    "\n",
    "X = df.drop(columns='target') <br>\n",
    "y = df['target'].values.reshape(-1,1)\n",
    "\n",
    "* train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state=0)\n",
    "\n",
    "* scaling feaures and target\n",
    "\n",
    "scaler = StandardScaler() <br>\n",
    "X_train = scaler.fit_transform(X_train) <br>\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "* ensemble method: RandomForestRegressor\n",
    "\n",
    "feature_names = X.columns <br>\n",
    "model = RandomForestRegressor(random_state=1)\n",
    "\n",
    "* feature importance\n",
    "\n",
    "model.fit(X_train,y_train) <br>\n",
    "importances = model.feature_importances_\n",
    "\n",
    "* saving to a dataframe\n",
    "\n",
    "X_importances = pd.DataFrame({\"Importance\":importances, \"Indicator\":feature_names}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "* cumulative sums\n",
    "\n",
    "X_importances['CumSum'] = X_importances['Importance'].cumsum(axis=0) <br>\n",
    "X_importances = X_importances.set_index(\"Indicator\")\n",
    "\n",
    "* displaying top ten most important features\n",
    "\n",
    "top_ten=X_importances.nlargest(n=10, columns=['Importance', 'CumSum']) <br>\n",
    "top_ten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0781274b",
   "metadata": {},
   "source": [
    "#### Feature Importance: Random Forest Classifier\n",
    "\n",
    "* Prepare Data\n",
    "\n",
    "X = df.drop(columns='target') <br>\n",
    "y = df['target'].values.reshape(-1,1)\n",
    "\n",
    "* train test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state=0)\n",
    "\n",
    "* scaling feaures and target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "* Fitting Standard Scaler\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "* Scaling data\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train) <br>\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "* Fitting the model\n",
    "\n",
    "model = model.fit(X_train_scaled, y_train)\n",
    "\n",
    "* Making predictions using the testing data\n",
    "\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "* Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "* Displaying results\n",
    "\n",
    "print(\"Confusion Matrix\") <br>\n",
    "display(cm_df) <br>\n",
    "print(f\"Accuracy Score : {acc_score}\") <br>\n",
    "print(\"Classification Report\") <br>\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "* feature importance\n",
    "\n",
    "importances = model.feature_importances_\n",
    "\n",
    "* saving to a dataframe\n",
    "\n",
    "X_importances = pd.DataFrame({\"Importance\":importances, \"Indicator\":feature_names}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "* cumulative sums\n",
    "\n",
    "X_importances['CumSum'] = X_importances['Importance'].cumsum(axis=0) <br>\n",
    "X_importances = X_importances.set_index(\"Indicator\")\n",
    "\n",
    "* displaying top ten most important features\n",
    "\n",
    "top_ten=X_importances.nlargest(n=10, columns=['Importance', 'CumSum']) <br>\n",
    "top_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db221ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c6886",
   "metadata": {},
   "source": [
    "#### PCA + Linear Regression\n",
    "\n",
    "X = df.drop(columns=['target']) <br>\n",
    "y = df[['target']]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler <br>\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "X_train = sc.fit_transform(X_train) <br>\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components = 100) <br>\n",
    "X_train = pca.fit_transform(X_train) <br>\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "regressor = LinearRegression() <br>\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test) <br>\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96efdda6",
   "metadata": {},
   "source": [
    "### Step 5: Model Data (50%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8697196",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc25ae32",
   "metadata": {},
   "source": [
    "* train test split\n",
    "* fit model\n",
    "* use model on X_test to predict y_test\n",
    "* score y_pred against y_test to measure model performance / evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddef6af",
   "metadata": {},
   "source": [
    "#### Logisitic Regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1),\n",
    "                                                   df['training'], test_size=0.2,\n",
    "                                                   random_state=200)\n",
    "* fitting model\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear') <br>\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = LogReg.predict(X_test)\n",
    "\n",
    "\n",
    "* Model Evaluation: Classification report without cross-validation\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "* K-fold cross-validation & confusion matrices\n",
    "\n",
    "y_train_pred = cross_val_predict(LogReg, X_train, y_train, cv=5) <br>\n",
    "confusion_matrix(y_train, y_train_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
